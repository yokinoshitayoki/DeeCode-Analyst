"""
æµ‹è¯•è’¸é¦åçš„æ¨¡å‹æ•ˆæœ
åœ¨AutoDLäº‘ç«¯ç¯å¢ƒä¸­è¿è¡Œ
"""
import os
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import time
import json

# AutoDLç¯å¢ƒé…ç½®
cache_dir = "/root/autodl-tmp/huggingface_cache"
os.environ['HF_HOME'] = cache_dir
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

def load_teacher_model():
    """åŠ è½½æ•™å¸ˆæ¨¡å‹"""
    print("ğŸ“ åŠ è½½æ•™å¸ˆæ¨¡å‹...")
    
    base_model_id = "Qwen/Qwen1.5-7B-Chat"
    adapter_path = "/root/autodl-tmp/models/deepcode-analyst-finetuned"
    
    tokenizer = AutoTokenizer.from_pretrained(
        base_model_id, 
        trust_remote_code=True,
        cache_dir=cache_dir
    )
    
    base_model = AutoModelForCausalLM.from_pretrained(
        base_model_id,
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True,
        cache_dir=cache_dir
    )
    
    teacher_model = PeftModel.from_pretrained(base_model, adapter_path)
    return teacher_model, tokenizer

def load_distilled_model():
    """åŠ è½½è’¸é¦æ¨¡å‹"""
    print("ğŸ”¬ åŠ è½½è’¸é¦æ¨¡å‹...")
    
    model_path = "/root/autodl-tmp/models/deepcode-analyst-distilled"
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"è’¸é¦æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
    
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True
    )
    
    student_model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True
    )
    
    return student_model, tokenizer

def generate_response(model, tokenizer, prompt, max_new_tokens=150):
    """ç”Ÿæˆæ¨¡å‹å“åº”"""
    device = next(model.parameters()).device
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    
    start_time = time.time()
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id
        )
    
    end_time = time.time()
    
    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
    generation_time = end_time - start_time
    
    return response.strip(), generation_time

def run_comparison_test():
    """è¿è¡Œå¯¹æ¯”æµ‹è¯•"""
    print("=" * 60)
    print("ğŸ§ª DeepCode-Analyst è’¸é¦æ•ˆæœæµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "é¡¹ç›®æ¶æ„åˆ†æ",
            "prompt": """### æŒ‡ä»¤:
æ ¹æ®æä¾›çš„ä»£ç åº“ç»“æ„åˆ†æï¼Œç”Ÿæˆä¸€ä»½å…³äºé¡¹ç›®æ•´ä½“æ¶æ„çš„æŠ€æœ¯æŠ¥å‘Š

### è¾“å…¥:
{"project_name": "E-commerce-API", "components": ["frontend", "backend", "database"], "key_files": ["app.py", "models.py", "api.js"]}

### è¾“å‡º:
"""
        },
        {
            "name": "å‡½æ•°åˆ†æ",
            "prompt": """### æŒ‡ä»¤:
è¯·æ·±å…¥åˆ†ææŒ‡å®šPythonå‡½æ•°çš„å†…éƒ¨å®ç°é€»è¾‘å’Œå‚æ•°

### è¾“å…¥:
{"function_name": "calculate_score", "parameters": ["data", "weights"], "complexity": "medium"}

### è¾“å‡º:
"""
        },
        {
            "name": "æ€§èƒ½ä¼˜åŒ–å»ºè®®",
            "prompt": """### æŒ‡ä»¤:
åˆ†æç»™å®šçš„ä»£ç ç‰‡æ®µï¼Œè¯†åˆ«æ€§èƒ½ç“¶é¢ˆå¹¶æä¾›ä¼˜åŒ–å»ºè®®

### è¾“å…¥:
{"code_snippet": "for item in large_list: result = expensive_operation(item)", "context": "å¤„ç†å¤§é‡æ•°æ®æ—¶æ€§èƒ½è¾ƒæ…¢"}

### è¾“å‡º:
"""
        }
    ]
    
    try:
        # åŠ è½½æ¨¡å‹
        teacher_model, teacher_tokenizer = load_teacher_model()
        distilled_model, distilled_tokenizer = load_distilled_model()
        
        # æ¨¡å‹å‚æ•°å¯¹æ¯”
        teacher_params = sum(p.numel() for p in teacher_model.parameters())
        distilled_params = sum(p.numel() for p in distilled_model.parameters())
        compression_ratio = teacher_params / distilled_params
        
        print(f"ğŸ“Š æ¨¡å‹å¯¹æ¯”:")
        print(f"   æ•™å¸ˆæ¨¡å‹å‚æ•°: {teacher_params:,}")
        print(f"   è’¸é¦æ¨¡å‹å‚æ•°: {distilled_params:,}")
        print(f"   å‹ç¼©æ¯”ä¾‹: {compression_ratio:.1f}x")
        print()
        
        # è¿è¡Œæµ‹è¯•
        results = []
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"ğŸ“ æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['name']}")
            print("-" * 50)
            
            prompt = test_case['prompt']
            
            # æ•™å¸ˆæ¨¡å‹
            print("ğŸ“ æ•™å¸ˆæ¨¡å‹å“åº”:")
            teacher_response, teacher_time = generate_response(teacher_model, teacher_tokenizer, prompt)
            print(f"â±ï¸  ç”Ÿæˆæ—¶é—´: {teacher_time:.2f}ç§’")
            print(f"ğŸ“„ å“åº”é•¿åº¦: {len(teacher_response)}å­—ç¬¦")
            print(f"ğŸ’¬ å†…å®¹é¢„è§ˆ: {teacher_response[:100]}...")
            print()
            
            # è’¸é¦æ¨¡å‹
            print("ğŸ”¬ è’¸é¦æ¨¡å‹å“åº”:")
            distilled_response, distilled_time = generate_response(distilled_model, distilled_tokenizer, prompt)
            print(f"â±ï¸  ç”Ÿæˆæ—¶é—´: {distilled_time:.2f}ç§’")
            print(f"ğŸ“„ å“åº”é•¿åº¦: {len(distilled_response)}å­—ç¬¦")
            print(f"ğŸ’¬ å†…å®¹é¢„è§ˆ: {distilled_response[:100]}...")
            print()
            
            # æ€§èƒ½å¯¹æ¯”
            speed_improvement = teacher_time / distilled_time if distilled_time > 0 else float('inf')
            length_retention = len(distilled_response) / len(teacher_response) if len(teacher_response) > 0 else 0
            
            print("ğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
            print(f"   é€Ÿåº¦æå‡: {speed_improvement:.1f}x")
            print(f"   é•¿åº¦ä¿ç•™: {length_retention:.1%}")
            
            # è´¨é‡è¯„ä¼°
            quality_score = 0
            if any(keyword in distilled_response for keyword in ['åˆ†æ', 'æŠ¥å‘Š', 'å»ºè®®', 'æŠ€æœ¯', 'æ¶æ„']):
                quality_score += 0.3
            if any(marker in distilled_response for marker in ['###', '**', '1.', '2.', '-', '*']):
                quality_score += 0.3
            if len(distilled_response) > 50:
                quality_score += 0.4
            
            print(f"   è´¨é‡è¯„åˆ†: {quality_score:.1%}")
            print()
            
            results.append({
                'test_case': test_case['name'],
                'teacher_time': teacher_time,
                'distilled_time': distilled_time,
                'speed_improvement': speed_improvement,
                'length_retention': length_retention,
                'quality_score': quality_score,
                'teacher_response': teacher_response,
                'distilled_response': distilled_response
            })
        
        # æ€»ä½“è¯„ä¼°
        print("=" * 60)
        print("ğŸ“Š æ€»ä½“è¯„ä¼°ç»“æœ")
        print("=" * 60)
        
        avg_speed = sum(r['speed_improvement'] for r in results) / len(results)
        avg_length = sum(r['length_retention'] for r in results) / len(results)
        avg_quality = sum(r['quality_score'] for r in results) / len(results)
        
        print(f"å¹³å‡é€Ÿåº¦æå‡: {avg_speed:.1f}x")
        print(f"å¹³å‡é•¿åº¦ä¿ç•™: {avg_length:.1%}")
        print(f"å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.1%}")
        print()
        
        # è’¸é¦æˆåŠŸåˆ¤å®š
        success_criteria = {
            'speed_improvement': avg_speed >= 2.0,
            'length_retention': avg_length >= 0.7,
            'quality_score': avg_quality >= 0.6
        }
        
        print("âœ… è’¸é¦æˆåŠŸæ ‡å‡†:")
        for criterion, passed in success_criteria.items():
            status = "âœ…" if passed else "âŒ"
            print(f"   {status} {criterion}: {'é€šè¿‡' if passed else 'æœªé€šè¿‡'}")
        
        overall_success = all(success_criteria.values())
        print(f"\nğŸ¯ æ•´ä½“è¯„ä¼°: {'ğŸ‰ è’¸é¦æˆåŠŸ!' if overall_success else 'âš ï¸ éœ€è¦ä¼˜åŒ–'}")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        test_results = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'model_comparison': {
                'teacher_params': teacher_params,
                'distilled_params': distilled_params,
                'compression_ratio': compression_ratio
            },
            'performance_metrics': {
                'avg_speed_improvement': avg_speed,
                'avg_length_retention': avg_length,
                'avg_quality_score': avg_quality
            },
            'success_criteria': success_criteria,
            'overall_success': overall_success,
            'detailed_results': results
        }
        
        result_path = "/root/autodl-tmp/models/deepcode-analyst-distilled/test_results.json"
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜: {result_path}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def quick_inference_test():
    """å¿«é€Ÿæ¨ç†æµ‹è¯•"""
    print("\nğŸš€ å¿«é€Ÿæ¨ç†æµ‹è¯•")
    print("-" * 30)
    
    try:
        distilled_model, tokenizer = load_distilled_model()
        
        test_prompt = """### æŒ‡ä»¤:
ç”Ÿæˆä»£ç åˆ†ææŠ¥å‘Š

### è¾“å…¥:
{"file": "main.py", "functions": 3, "complexity": "low"}

### è¾“å‡º:
"""
        
        response, inference_time = generate_response(distilled_model, tokenizer, test_prompt, max_new_tokens=100)
        
        print(f"â±ï¸  æ¨ç†æ—¶é—´: {inference_time:.3f}ç§’")
        print(f"ğŸ“„ ç”Ÿæˆé•¿åº¦: {len(response)}å­—ç¬¦")
        print("\nğŸ’¬ ç”Ÿæˆå†…å®¹:")
        print("-" * 30)
        print(response)
        print("-" * 30)
        print("âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ DeepCode-Analyst è’¸é¦æ¨¡å‹æµ‹è¯•")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    distilled_path = "/root/autodl-tmp/models/deepcode-analyst-distilled"
    teacher_path = "/root/autodl-tmp/models/deepcode-analyst-finetuned"
    
    if not os.path.exists(distilled_path):
        print(f"âŒ è’¸é¦æ¨¡å‹ä¸å­˜åœ¨: {distilled_path}")
        print("è¯·å…ˆè¿è¡ŒçŸ¥è¯†è’¸é¦")
        return
    
    if not os.path.exists(teacher_path):
        print(f"âš ï¸  æ•™å¸ˆæ¨¡å‹ä¸å­˜åœ¨: {teacher_path}")
        print("å°†åªè¿è¡Œè’¸é¦æ¨¡å‹çš„å¿«é€Ÿæµ‹è¯•")
        quick_inference_test()
        return
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”æµ‹è¯•
    run_comparison_test()

if __name__ == "__main__":
    main()