#!/bin/bash
# ä¸€é”®éƒ¨ç½²è„šæœ¬ - åœ¨AutoDLæœåŠ¡å™¨ä¸Šç›´æ¥è¿è¡Œ
# ä½¿ç”¨æ–¹æ³•: å¤åˆ¶æ­¤è„šæœ¬å†…å®¹ï¼Œåœ¨AutoDLæœåŠ¡å™¨ç»ˆç«¯ä¸­ç²˜è´´æ‰§è¡Œ

set -e

echo "ğŸš€ å¼€å§‹DeepCode-Analystä¸€é”®éƒ¨ç½²..."
echo "æœåŠ¡å™¨ä¿¡æ¯: $(hostname) - $(whoami)"

# 1. æ›´æ–°ç³»ç»Ÿå’Œå®‰è£…åŸºç¡€å·¥å…·
echo "ğŸ“¦ å®‰è£…ç³»ç»Ÿä¾èµ–..."
apt-get update -qq
apt-get install -y -qq git wget curl vim htop tmux tree build-essential python3-dev python3-pip

# 2. æ£€æŸ¥GPU
echo "ğŸ® æ£€æŸ¥GPUçŠ¶æ€..."
nvidia-smi

# 3. å®‰è£…/é…ç½®Conda
echo "ğŸ è®¾ç½®Condaç¯å¢ƒ..."
if ! command -v conda &> /dev/null; then
    echo "å®‰è£…Miniconda..."
    wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
    bash ~/miniconda.sh -b -p $HOME/miniconda
    export PATH="$HOME/miniconda/bin:$PATH"
    conda init bash
    source ~/.bashrc
fi

# åˆ›å»ºPythonç¯å¢ƒ
conda create -n deepcode python=3.9 -y
source ~/miniconda/etc/profile.d/conda.sh
conda activate deepcode

# 4. æ£€æŸ¥é¡¹ç›®ç›®å½•
PROJECT_DIR="/root/DeepCode-Analyst"
if [ ! -d "$PROJECT_DIR" ]; then
    echo "âŒ é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: $PROJECT_DIR"
    echo "è¯·å…ˆä¸Šä¼ é¡¹ç›®æ–‡ä»¶åˆ°æœåŠ¡å™¨"
    echo ""
    echo "ä¸Šä¼ æ–¹æ³•1 - æœ¬åœ°æ‰§è¡Œ:"
    echo "scp -P 18812 -r ./DeepCode-Analyst root@connect.bjb1.seetacloud.com:/root/"
    echo ""
    echo "ä¸Šä¼ æ–¹æ³•2 - ä½¿ç”¨å·¥å…·:"
    echo "python upload_to_autodl.py"
    echo ""
    read -p "é¡¹ç›®æ–‡ä»¶ä¸Šä¼ å®ŒæˆåæŒ‰Enterç»§ç»­..."
    
    if [ ! -d "$PROJECT_DIR" ]; then
        echo "âŒ é¡¹ç›®ç›®å½•ä»ä¸å­˜åœ¨ï¼Œé€€å‡ºéƒ¨ç½²"
        exit 1
    fi
fi

cd $PROJECT_DIR

# 5. å®‰è£…Pythonä¾èµ–
echo "ğŸ“š å®‰è£…Pythonä¾èµ–..."
python -m pip install --upgrade pip

# å®‰è£…PyTorch (CUDAç‰ˆæœ¬)
echo "å®‰è£…PyTorch..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
for req_file in "requirements_autodl.txt" "finetuning/requirements.txt" "requirements.txt"; do
    if [ -f "$req_file" ]; then
        echo "å®‰è£… $req_file"
        python -m pip install -r "$req_file"
    fi
done

# 6. éªŒè¯å®‰è£…
echo "âœ… éªŒè¯å®‰è£…..."
python -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPUæ•°é‡: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
"

# 7. å‡†å¤‡è®­ç»ƒæ•°æ®
echo "ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®..."
if [ ! -f "finetuning/training_data.jsonl" ]; then
    python finetuning/prepare_dataset.py --mode sample --num-samples 50 --output-path ./finetuning/training_data.jsonl
fi

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if [ -f "finetuning/training_data.jsonl" ]; then
    SAMPLE_COUNT=$(wc -l < finetuning/training_data.jsonl)
    echo "âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆï¼ŒåŒ…å« $SAMPLE_COUNT ä¸ªæ ·æœ¬"
else
    echo "âŒ è®­ç»ƒæ•°æ®ç”Ÿæˆå¤±è´¥"
    exit 1
fi

# 8. æ£€æµ‹GPUæ˜¾å­˜å¹¶åˆ›å»ºé…ç½®
echo "âš™ï¸ åˆ›å»ºè®­ç»ƒé…ç½®..."
GPU_MEMORY=8192
if command -v nvidia-smi &> /dev/null; then
    GPU_MEMORY=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -n1)
fi

echo "æ£€æµ‹åˆ°GPUæ˜¾å­˜: ${GPU_MEMORY}MB"

# æ ¹æ®æ˜¾å­˜è°ƒæ•´é…ç½®
if [ "$GPU_MEMORY" -lt 8192 ]; then
    BATCH_SIZE=1
    GRAD_ACCUM=16
    MAX_LEN=1024
    LORA_R=8
    echo "ä½¿ç”¨å°æ˜¾å­˜é…ç½®"
elif [ "$GPU_MEMORY" -lt 16384 ]; then
    BATCH_SIZE=1
    GRAD_ACCUM=8
    MAX_LEN=2048
    LORA_R=16
    echo "ä½¿ç”¨æ ‡å‡†é…ç½®"
else
    BATCH_SIZE=2
    GRAD_ACCUM=4
    MAX_LEN=2048
    LORA_R=32
    echo "ä½¿ç”¨é«˜æ€§èƒ½é…ç½®"
fi

# 9. åˆ›å»ºå¯åŠ¨è„šæœ¬
echo "ğŸ“ åˆ›å»ºè®­ç»ƒå¯åŠ¨è„šæœ¬..."
cat > start_training.sh << EOF
#!/bin/bash
source ~/miniconda/etc/profile.d/conda.sh
conda activate deepcode
cd $PROJECT_DIR

echo "å¼€å§‹å¾®è°ƒè®­ç»ƒ..."
echo "é…ç½®: batch_size=$BATCH_SIZE, max_length=$MAX_LEN, lora_r=$LORA_R"

python finetuning/run_finetune.py \\
    --model_id "Qwen/Qwen1.5-7B-Chat" \\
    --dataset_path "./finetuning/training_data.jsonl" \\
    --output_dir "./models/deepcode-analyst-finetuned" \\
    --batch_size $BATCH_SIZE \\
    --gradient_accumulation_steps $GRAD_ACCUM \\
    --num_epochs 3 \\
    --learning_rate 2e-5 \\
    --max_length $MAX_LEN \\
    --lora_r $LORA_R \\
    --lora_alpha 32 \\
    --lora_dropout 0.05

echo "å¾®è°ƒå®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨: ./models/deepcode-analyst-finetuned/"
EOF

chmod +x start_training.sh

# 10. åˆ›å»ºç®¡ç†è„šæœ¬
cat > manage.sh << EOF
#!/bin/bash
case "\$1" in
    start)
        echo "å¯åŠ¨è®­ç»ƒä¼šè¯..."
        tmux new-session -d -s training "cd $PROJECT_DIR && source ~/miniconda/etc/profile.d/conda.sh && conda activate deepcode && ./start_training.sh"
        echo "è®­ç»ƒå·²åœ¨åå°å¯åŠ¨ï¼Œä½¿ç”¨ './manage.sh status' æŸ¥çœ‹çŠ¶æ€"
        ;;
    status)
        if tmux has-session -t training 2>/dev/null; then
            echo "è®­ç»ƒæ­£åœ¨è¿è¡Œ..."
            tmux capture-pane -t training -p | tail -n 5
        else
            echo "è®­ç»ƒæœªè¿è¡Œ"
        fi
        ;;
    attach)
        tmux attach -t training
        ;;
    stop)
        tmux kill-session -t training 2>/dev/null || echo "è®­ç»ƒä¼šè¯ä¸å­˜åœ¨"
        ;;
    gpu)
        watch -n 1 nvidia-smi
        ;;
    *)
        echo "ç”¨æ³•: \$0 {start|status|attach|stop|gpu}"
        echo "  start  - åå°å¯åŠ¨è®­ç»ƒ"
        echo "  status - æŸ¥çœ‹è®­ç»ƒçŠ¶æ€"  
        echo "  attach - è¿æ¥åˆ°è®­ç»ƒä¼šè¯"
        echo "  stop   - åœæ­¢è®­ç»ƒ"
        echo "  gpu    - ç›‘æ§GPUä½¿ç”¨"
        ;;
esac
EOF

chmod +x manage.sh

# 11. åˆ›å»ºç¯å¢ƒæ–‡ä»¶
cat > .env << EOF
# ç¯å¢ƒå˜é‡é…ç½®
CUDA_VISIBLE_DEVICES=0
TOKENIZERS_PARALLELISM=false
PROJECT_ROOT=$PROJECT_DIR
EOF

echo ""
echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
echo ""
echo "ğŸ“‹ ä½¿ç”¨è¯´æ˜ï¼š"
echo "1. ç›´æ¥å¼€å§‹è®­ç»ƒ:     ./start_training.sh"
echo "2. åå°å¯åŠ¨è®­ç»ƒ:     ./manage.sh start"
echo "3. æŸ¥çœ‹è®­ç»ƒçŠ¶æ€:     ./manage.sh status"
echo "4. è¿æ¥è®­ç»ƒä¼šè¯:     ./manage.sh attach"
echo "5. åœæ­¢è®­ç»ƒ:         ./manage.sh stop"
echo "6. ç›‘æ§GPU:          ./manage.sh gpu"
echo ""
echo "ğŸ“ é‡è¦è·¯å¾„ï¼š"
echo "  é¡¹ç›®ç›®å½•: $PROJECT_DIR"
echo "  è®­ç»ƒæ•°æ®: $PROJECT_DIR/finetuning/training_data.jsonl"
echo "  æ¨¡å‹è¾“å‡º: $PROJECT_DIR/models/deepcode-analyst-finetuned/"
echo ""
echo "ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼å»ºè®®å…ˆè¿è¡Œ: ./manage.sh start"
