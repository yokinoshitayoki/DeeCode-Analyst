"""
DeepCode-Analyst 0.5Bå­¦ç”Ÿæ¨¡å‹ Webç•Œé¢
åŸºäºGradioçš„å‹å¥½äº¤äº’ç•Œé¢
"""
import os
import sys
import torch
import warnings
from pathlib import Path
import json
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

class WebInterface:
    """Webç•Œé¢ç±»"""
    
    def __init__(self):
        self.cloud_data_dir = Path(__file__).parent.parent
        self.adapter_path = self.cloud_data_dir / "models" / "student_0.5b"
        self.model = None
        self.tokenizer = None
        self.device = None
        
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            from transformers import AutoTokenizer, AutoModelForCausalLM
            from peft import PeftModel
            
            print("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹...")
            
            # æ£€æµ‹è®¾å¤‡
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            torch_dtype = torch.float16 if self.device == "cuda" else torch.float32
            device_map = "auto" if self.device == "cuda" else "cpu"
            
            # åŠ è½½åˆ†è¯å™¨
            self.tokenizer = AutoTokenizer.from_pretrained(
                "Qwen/Qwen1.5-0.5B-Chat",
                trust_remote_code=True
            )
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # åŠ è½½åŸºç¡€æ¨¡å‹
            base_model = AutoModelForCausalLM.from_pretrained(
                "Qwen/Qwen1.5-0.5B-Chat",
                torch_dtype=torch_dtype,
                device_map=device_map,
                trust_remote_code=True,
                low_cpu_mem_usage=True
            )
            
            # åŠ è½½LoRAé€‚é…å™¨
            self.model = PeftModel.from_pretrained(
                base_model, 
                str(self.adapter_path)
            )
            
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ!")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def generate_response(self, prompt, max_tokens=200, temperature=0.7, top_p=0.9):
        """ç”Ÿæˆå›åº”"""
        if not self.model or not self.tokenizer:
            return "âŒ æ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"
        
        try:
            # æ ¼å¼åŒ–è¾“å…¥
            formatted_prompt = f"""### æŒ‡ä»¤:
ä½œä¸ºä»£ç åˆ†æä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹å†…å®¹å¹¶æä¾›ä¸“ä¸šå»ºè®®

### è¾“å…¥:
{prompt}

### è¾“å‡º:
"""
            
            # ç¼–ç 
            device = next(self.model.parameters()).device
            inputs = self.tokenizer(formatted_prompt, return_tensors="pt")
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            # ç”Ÿæˆ
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.1
                )
            
            # è§£ç 
            response = self.tokenizer.decode(
                outputs[0][inputs['input_ids'].shape[1]:], 
                skip_special_tokens=True
            )
            
            return response.strip()
            
        except Exception as e:
            return f"âŒ ç”Ÿæˆå¤±è´¥: {e}"
    
    def create_gradio_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        try:
            import gradio as gr
        except ImportError:
            print("âŒ Gradioæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install gradio")
            return None
        
        def chat_function(message, history, max_tokens, temperature, top_p):
            """èŠå¤©å‡½æ•°"""
            if not message.strip():
                return history, ""
            
            # ç”Ÿæˆå›åº”
            response = self.generate_response(
                message, 
                max_tokens=max_tokens, 
                temperature=temperature,
                top_p=top_p
            )
            
            # æ›´æ–°å†å²
            history.append([message, response])
            
            return history, ""
        
        def clear_history():
            """æ¸…é™¤å†å²"""
            return [], ""
        
        def load_example(example):
            """åŠ è½½ç¤ºä¾‹"""
            return example
        
        # åˆ›å»ºç•Œé¢
        with gr.Blocks(
            title="DeepCode-Analyst 0.5B",
            theme=gr.themes.Soft(),
            css="""
            .gradio-container {
                max-width: 1200px !important;
            }
            .chat-message {
                padding: 10px;
                margin: 5px;
                border-radius: 10px;
            }
            """
        ) as interface:
            
            gr.Markdown("""
            # ğŸ¤– DeepCode-Analyst 0.5B å­¦ç”Ÿæ¨¡å‹
            
            åŸºäºçŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œå°†7Bæ•™å¸ˆæ¨¡å‹çš„ä»£ç åˆ†æèƒ½åŠ›å‹ç¼©åˆ°0.5Bå‚æ•°ã€‚
            
            **ä¸“é•¿é¢†åŸŸ**: ä»£ç åˆ†æã€æ€§èƒ½ä¼˜åŒ–ã€ç®—æ³•è§£é‡Šã€ä»£ç é‡æ„å»ºè®®
            """)
            
            with gr.Row():
                with gr.Column(scale=3):
                    # èŠå¤©ç•Œé¢
                    chatbot = gr.Chatbot(
                        label="ğŸ’¬ å¯¹è¯",
                        height=400,
                        show_label=True,
                        container=True
                    )
                    
                    with gr.Row():
                        msg = gr.Textbox(
                            label="è¾“å…¥æ‚¨çš„é—®é¢˜",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„ä»£ç åˆ†æéœ€æ±‚...",
                            lines=3,
                            scale=4
                        )
                        submit_btn = gr.Button("å‘é€", variant="primary", scale=1)
                    
                    with gr.Row():
                        clear_btn = gr.Button("æ¸…é™¤å¯¹è¯", variant="secondary")
                        
                with gr.Column(scale=1):
                    # å‚æ•°è®¾ç½®
                    gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")
                    
                    max_tokens = gr.Slider(
                        minimum=50,
                        maximum=500,
                        value=200,
                        step=10,
                        label="æœ€å¤§ç”Ÿæˆé•¿åº¦"
                    )
                    
                    temperature = gr.Slider(
                        minimum=0.1,
                        maximum=2.0,
                        value=0.7,
                        step=0.1,
                        label="åˆ›é€ æ€§ (Temperature)"
                    )
                    
                    top_p = gr.Slider(
                        minimum=0.1,
                        maximum=1.0,
                        value=0.9,
                        step=0.1,
                        label="å¤šæ ·æ€§ (Top-p)"
                    )
                    
                    # ç¤ºä¾‹
                    gr.Markdown("### ğŸ“ ç¤ºä¾‹é—®é¢˜")
                    
                    examples = [
                        "åˆ†æè¿™æ®µä»£ç çš„æ—¶é—´å¤æ‚åº¦ï¼š\ndef find_max(arr):\n    max_val = arr[0]\n    for i in range(1, len(arr)):\n        if arr[i] > max_val:\n            max_val = arr[i]\n    return max_val",
                        "å¦‚ä½•ä¼˜åŒ–è¿™ä¸ªå¾ªç¯ï¼š\nresult = []\nfor i in range(len(data)):\n    if data[i] > 0:\n        result.append(data[i] * 2)",
                        "è§£é‡Šè¿™ä¸ªæ’åºç®—æ³•çš„å·¥ä½œåŸç†ï¼š\ndef bubble_sort(arr):\n    n = len(arr)\n    for i in range(n):\n        for j in range(0, n-i-1):\n            if arr[j] > arr[j+1]:\n                arr[j], arr[j+1] = arr[j+1], arr[j]"
                    ]
                    
                    for i, example in enumerate(examples, 1):
                        example_btn = gr.Button(
                            f"ç¤ºä¾‹ {i}", 
                            variant="outline",
                            size="sm"
                        )
                        example_btn.click(
                            fn=load_example,
                            inputs=[gr.State(example)],
                            outputs=[msg]
                        )
            
            # ç³»ç»Ÿä¿¡æ¯
            with gr.Accordion("ğŸ”§ ç³»ç»Ÿä¿¡æ¯", open=False):
                device_info = f"è¿è¡Œè®¾å¤‡: {self.device.upper()}"
                if self.device == "cuda":
                    gpu_name = torch.cuda.get_device_name(0)
                    device_info += f" ({gpu_name})"
                
                gr.Markdown(f"""
                **æ¨¡å‹ä¿¡æ¯**:
                - åŸºç¡€æ¨¡å‹: Qwen1.5-0.5B-Chat
                - é€‚é…å™¨: LoRAçŸ¥è¯†è’¸é¦
                - æ•™å¸ˆæ¨¡å‹: Qwen1.5-7B-Chat (å¾®è°ƒ)
                - {device_info}
                - å‚æ•°é‡: ~0.5B
                - ä¸“ä¸šé¢†åŸŸ: ä»£ç åˆ†æä¸ä¼˜åŒ–
                """)
            
            # ç»‘å®šäº‹ä»¶
            submit_btn.click(
                fn=chat_function,
                inputs=[msg, chatbot, max_tokens, temperature, top_p],
                outputs=[chatbot, msg]
            )
            
            msg.submit(
                fn=chat_function,
                inputs=[msg, chatbot, max_tokens, temperature, top_p],
                outputs=[chatbot, msg]
            )
            
            clear_btn.click(
                fn=clear_history,
                outputs=[chatbot, msg]
            )
        
        return interface
    
    def create_streamlit_interface(self):
        """åˆ›å»ºStreamlitç•Œé¢"""
        try:
            import streamlit as st
        except ImportError:
            print("âŒ Streamlitæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install streamlit")
            return None
        
        st.set_page_config(
            page_title="DeepCode-Analyst 0.5B",
            page_icon="ğŸ¤–",
            layout="wide"
        )
        
        st.title("ğŸ¤– DeepCode-Analyst 0.5B å­¦ç”Ÿæ¨¡å‹")
        st.markdown("åŸºäºçŸ¥è¯†è’¸é¦çš„ä»£ç åˆ†æAIåŠ©æ‰‹")
        
        # ä¾§è¾¹æ è®¾ç½®
        with st.sidebar:
            st.header("âš™ï¸ è®¾ç½®")
            
            max_tokens = st.slider("æœ€å¤§ç”Ÿæˆé•¿åº¦", 50, 500, 200, 10)
            temperature = st.slider("åˆ›é€ æ€§", 0.1, 2.0, 0.7, 0.1)
            top_p = st.slider("å¤šæ ·æ€§", 0.1, 1.0, 0.9, 0.1)
            
            st.header("ğŸ“ ç¤ºä¾‹")
            if st.button("ä»£ç å¤æ‚åº¦åˆ†æ"):
                st.session_state.example_input = "åˆ†æè¿™æ®µä»£ç çš„æ—¶é—´å¤æ‚åº¦ï¼š\ndef linear_search(arr, target):\n    for i in range(len(arr)):\n        if arr[i] == target:\n            return i\n    return -1"
            
            if st.button("æ€§èƒ½ä¼˜åŒ–å»ºè®®"):
                st.session_state.example_input = "å¦‚ä½•ä¼˜åŒ–è¿™æ®µä»£ç ï¼š\nresult = []\nfor item in data:\n    if item > 0:\n        result.append(item * 2)"
        
        # ä¸»ç•Œé¢
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
        
        # è¾“å…¥æ¡†
        user_input = st.text_area(
            "è¾“å…¥æ‚¨çš„é—®é¢˜:",
            value=st.session_state.get('example_input', ''),
            height=100,
            placeholder="è¯·è¾“å…¥æ‚¨çš„ä»£ç åˆ†æéœ€æ±‚..."
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            if st.button("ğŸš€ åˆ†æ", type="primary"):
                if user_input.strip():
                    with st.spinner("æ­£åœ¨åˆ†æ..."):
                        response = self.generate_response(
                            user_input,
                            max_tokens=max_tokens,
                            temperature=temperature,
                            top_p=top_p
                        )
                        
                        st.session_state.chat_history.append({
                            "user": user_input,
                            "assistant": response,
                            "timestamp": datetime.now().strftime("%H:%M:%S")
                        })
        
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å†å²"):
                st.session_state.chat_history = []
                st.experimental_rerun()
        
        # æ˜¾ç¤ºå¯¹è¯å†å²
        if st.session_state.chat_history:
            st.header("ğŸ’¬ å¯¹è¯å†å²")
            
            for i, chat in enumerate(reversed(st.session_state.chat_history[-5:])):  # åªæ˜¾ç¤ºæœ€è¿‘5æ¡
                with st.expander(f"å¯¹è¯ {len(st.session_state.chat_history)-i} ({chat['timestamp']})"):
                    st.markdown(f"**ğŸ‘¤ ç”¨æˆ·**: {chat['user']}")
                    st.markdown(f"**ğŸ¤– åŠ©æ‰‹**: {chat['assistant']}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ å¯åŠ¨DeepCode-Analyst Webç•Œé¢...")
    
    # åˆ›å»ºWebç•Œé¢å®ä¾‹
    web_interface = WebInterface()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not web_interface.adapter_path.exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {web_interface.adapter_path}")
        print("ğŸ’¡ è¯·å…ˆä¸‹è½½å­¦ç”Ÿæ¨¡å‹æ–‡ä»¶")
        return
    
    # åŠ è½½æ¨¡å‹
    if not web_interface.load_model():
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        return
    
    # é€‰æ‹©ç•Œé¢ç±»å‹
    print("\nğŸ® é€‰æ‹©Webç•Œé¢ç±»å‹:")
    print("1. Gradio (æ¨è) - ç°ä»£åŒ–èŠå¤©ç•Œé¢")
    print("2. Streamlit - ä¼ ç»ŸWebåº”ç”¨ç•Œé¢")
    
    try:
        choice = input("è¯·é€‰æ‹© (1/2ï¼Œé»˜è®¤1): ").strip() or "1"
        
        if choice == "1":
            # Gradioç•Œé¢
            interface = web_interface.create_gradio_interface()
            if interface:
                print("ğŸš€ å¯åŠ¨Gradioç•Œé¢...")
                interface.launch(
                    server_name="0.0.0.0",
                    server_port=7860,
                    share=False,
                    inbrowser=True
                )
            
        elif choice == "2":
            # Streamlitç•Œé¢
            print("ğŸš€ å¯åŠ¨Streamlitç•Œé¢...")
            print("è¯·åœ¨æ–°ç»ˆç«¯è¿è¡Œ: streamlit run cloud_data/scripts/web_interface.py")
            
            # åˆ›å»ºStreamlitåº”ç”¨
            web_interface.create_streamlit_interface()
            
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Webç•Œé¢å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")

if __name__ == "__main__":
    main()